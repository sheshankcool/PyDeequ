{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmq4iyVS4nXU2rQT0WVkux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheshankcool/PyDeequ/blob/main/PyDeequ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WBs-5ze6NPKs"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "Hmhi2POhNRU2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        ""
      ],
      "metadata": {
        "id": "H7YQbfklNjYt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pydeequ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eqFkyO9NrSF",
        "outputId": "aa0812d4-90f6-4cd7-d7a7-60feba8b9e5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydeequ\n",
            "  Downloading pydeequ-1.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from pydeequ) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from pydeequ) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23.0->pydeequ) (1.17.0)\n",
            "Downloading pydeequ-1.4.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: pydeequ\n",
            "Successfully installed pydeequ-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i42P-EDANvB5",
        "outputId": "b39a64a0-d4b3-4056-9e7d-482f197ca34c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.1\n",
            "  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.1)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767581 sha256=b869fb91e65eb38cee708c4ba33398e98e3a6fabbf5cc40b19d6769de9769278\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/3f/72/8efd988f9ae041f051c75e6834cd92dd6d13a726e206e8b6f3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.3\n",
            "    Uninstalling pyspark-3.5.3:\n",
            "      Successfully uninstalled pyspark-3.5.3\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SPARK_VERSION'] = '3.1.1'"
      ],
      "metadata": {
        "id": "GEK8AV0eN27l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "import pydeequ\n",
        "spark = (SparkSession\n",
        "             .builder\n",
        "             .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
        "             .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
        "             .getOrCreate())"
      ],
      "metadata": {
        "id": "-VFYgdMgOCxg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = spark.sparkContext.parallelize([\n",
        "    Row(a=\"foo\", b=1, c=5, d=10, e=None, f=0),\n",
        "    Row(a=\"bar\", b=2, c=6, d=4, e= 12, f=90),\n",
        "    Row(a=\"baz\", b=3, c=None, d=None, e = 20, f= -10),\n",
        "    Row(a=\"cab\", b=3, c=8,  d=None, e =None, f=50)]).toDF()\n",
        ""
      ],
      "metadata": {
        "id": "QgCm7V96OGA2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")"
      ],
      "metadata": {
        "id": "qUlPCf1DSRyO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#"
      ],
      "metadata": {
        "id": "GVV96QFySWBn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasSize(lambda x: x == 4).hasSize(lambda x:x<=2))\\\n",
        " .run()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2cMOkBQUg-s",
        "outputId": "6e727cb9-0b2a-499c-9dcf-14d35f9c657f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Callback server started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftweeJViUnMN",
        "outputId": "7cfd6a76-c4cb-4aa6-e85b-59d685e98429"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                |constraint_status|constraint_message                                |\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |SizeConstraint(Size(None))|Success          |                                                  |\n",
            "|Basic Check|Warning    |Warning     |SizeConstraint(Size(None))|Failure          |Value: 4 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### check if the number of columns are as the required number"
      ],
      "metadata": {
        "id": "kUQ4GulCWzcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasSize(lambda x: x == 5))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS-6Vs5hUuM-",
        "outputId": "13d7fdfe-5f7a-4c34-b451-b84d4917b75e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                |constraint_status|constraint_message                                |\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |SizeConstraint(Size(None))|Failure          |Value: 4 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check if there are missing values in given columns\n",
        "- value is 0.75 because it divides non null rows/total rows since 1/4 which is 0.75 which means that only 75% are not null but not 100% which is 1.0. here it will compare the division output with 1 if it is not equal it will raise error."
      ],
      "metadata": {
        "id": "cSx8fBplW8NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isComplete('a')\\\n",
        "           .isComplete('b')\\\n",
        "           .isComplete('c')\\\n",
        "           .isComplete('d')\\\n",
        "           .isComplete('e')\\\n",
        "           .isComplete('f'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFmFWbX2VOLK",
        "outputId": "02226967-e343-4e72-d668-7e3b8bb64526"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(a,None,None))|Success          |                                                     |\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(b,None,None))|Success          |                                                     |\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(c,None,None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(d,None,None))|Failure          |Value: 0.5 does not meet the constraint requirement! |\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(e,None,None))|Failure          |Value: 0.5 does not meet the constraint requirement! |\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(f,None,None))|Success          |                                                     |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking for nullvalues on multiplecolumns at a time\n",
        "- where there should not be null values in all the given columns, it raises error if there is null value in atlease one of given column"
      ],
      "metadata": {
        "id": "2KzitP25YEbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areComplete(['a','b']))\\\n",
        " .addCheck(check.areComplete(['a','c','d']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX5bjONtV9AO",
        "outputId": "35903209-a12b-4f65-9a8a-20ea747ee04d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                                                 |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(Combined Completeness,((a IS NOT NULL) AND (b IS NOT NULL)),None,List(a, b),None))                         |Success          |                                                    |\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(Combined Completeness,((a IS NOT NULL) AND (b IS NOT NULL)),None,List(a, b),None))                         |Success          |                                                    |\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(Combined Completeness,(((a IS NOT NULL) AND (c IS NOT NULL)) AND (d IS NOT NULL)),None,List(a, c, d),None))|Failure          |Value: 0.5 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdTqhO4vYRLI",
        "outputId": "d6a3790f-7984-45db-96a3-d36deb35833b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hasCompleteness\n",
        "- will check what is the percentage of non null columns"
      ],
      "metadata": {
        "id": "P4gGlqwPaCqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasCompleteness('a',lambda x: x >= 0.8))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn7khiCWZq4J",
        "outputId": "20f81381-d9d2-4dab-bb39-c7e00c23779a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |CompletenessConstraint(Completeness(a,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasCompleteness('c',lambda x: x >= 0.75))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVdnbRkvZuRz",
        "outputId": "90f6df23-7a1c-4d48-f306-fbbb9994fcf3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |CompletenessConstraint(Completeness(c,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasCompleteness('c',lambda x: x >= 0.75))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMxREr-yZ2W2",
        "outputId": "627e8cdd-aa0e-4d95-befd-bc5911831c64"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |CompletenessConstraint(Completeness(c,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### check for duplicates\n"
      ],
      "metadata": {
        "id": "Pm0PaVMsbsLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isUnique('a'))\\\n",
        " .addCheck(check.isUnique('b'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A5dnUIabrrk",
        "outputId": "acd1f447-d045-44dd-94d9-22545bfb49cc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                         |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Success     |UniquenessConstraint(Uniqueness(List(a),None,None))|Success          |                                                    |\n",
            "|Basic Check|Warning    |Warning     |UniquenessConstraint(Uniqueness(List(a),None,None))|Success          |                                                    |\n",
            "|Basic Check|Warning    |Warning     |UniquenessConstraint(Uniqueness(List(b),None,None))|Failure          |Value: 0.5 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasUniqueness(['a'],lambda x : x > 0.75))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHWTO5anchhT",
        "outputId": "e8cb3e41-6e57-4b26-8ff8-b5cfe0ce7f09"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                              |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |UniquenessConstraint(Uniqueness(Stream(a, ?),None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qa011Be_c3ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA3BdtBCc91j",
        "outputId": "685dbc81-f264-41b1-c675-78ef15f96459"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasMin('b',lambda x : x <= 2))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaObSsDrc2pM",
        "outputId": "7d74a0ef-8b23-4110-8752-b85c6f274bd7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                             |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |MinimumConstraint(Minimum(b,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasMin('f',lambda x : x >= 1))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRy-BxtSbuYe",
        "outputId": "815d907c-f1d0-498d-b47f-22a5248e029d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                             |constraint_status|constraint_message                                    |\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |MinimumConstraint(Minimum(f,None,None))|Failure          |Value: -10.0 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasMax('f',lambda x : x <= 100))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuf4fjPbct25",
        "outputId": "9ce74390-379b-4517-f0bd-b0a5a57d3e15"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                             |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |MaximumConstraint(Maximum(f,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isPositive('a').isNonNegative('a').isPositive('b').isNonNegative('b')) \\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rys7FZjjde_b",
        "outputId": "627753e5-fee0-42f8-81a0-74c40898533a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                         |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(a is positive,COALESCE(CAST(a AS DECIMAL(20,10)), 1.0) > 0,None,List(a),None))     |Success          |                  |\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(a is non-negative,COALESCE(CAST(a AS DECIMAL(20,10)), 0.0) >= 0,None,List(a),None))|Success          |                  |\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(b is positive,COALESCE(CAST(b AS DECIMAL(20,10)), 1.0) > 0,None,List(b),None))     |Success          |                  |\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(b is non-negative,COALESCE(CAST(b AS DECIMAL(20,10)), 0.0) >= 0,None,List(b),None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isContainedIn(\"a\", [\"foo\", \"bar\", \"baz\"]))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kPIPKQMXdMF",
        "outputId": "723d704c-0e09-4789-c368-c99a76a5d744"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                              |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(a contained in foo,bar,baz,`a` IS NULL OR `a` IN ('foo','bar','baz'),None,List(a),None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasDataType(\"c\",ConstrainableDataTypes.Numeric))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiqsTyBee-sq",
        "outputId": "76c54fc4-9d0b-4225-f194-bb6898303c22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+----------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                  |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |AnalysisBasedConstraint(DataType(c,None),<function1>,Some(<function1>),None)|Success          |                  |\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdogHAyOedNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}